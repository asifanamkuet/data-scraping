{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fc0181d-346e-422f-9deb-9675a3bf88f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching page 1...\n",
      "Attempt 1 of 50...\n",
      "ChromeDriver options configured successfully.\n",
      "ChromeDriver initialized successfully.\n",
      "Stealth techniques applied successfully.\n",
      "Sleeping for 2.10 seconds...\n",
      "No reviews found on attempt 1. Retrying...\n",
      "Sleeping for 8.48 seconds...\n",
      "Attempt 2 of 50...\n",
      "ChromeDriver options configured successfully.\n",
      "ChromeDriver initialized successfully.\n",
      "Stealth techniques applied successfully.\n",
      "Sleeping for 4.14 seconds...\n",
      "No reviews found on attempt 2. Retrying...\n",
      "Sleeping for 5.42 seconds...\n",
      "Attempt 3 of 50...\n",
      "ChromeDriver options configured successfully.\n",
      "ChromeDriver initialized successfully.\n",
      "Stealth techniques applied successfully.\n",
      "Sleeping for 4.04 seconds...\n",
      "Successfully extracted 10 reviews.\n",
      "Reviews extracted from page 1: 10\n",
      "Sleeping for 4.27 seconds...\n",
      "Fetching page 2...\n",
      "Attempt 1 of 50...\n",
      "ChromeDriver options configured successfully.\n",
      "ChromeDriver initialized successfully.\n",
      "Stealth techniques applied successfully.\n",
      "Sleeping for 2.05 seconds...\n",
      "Error during review fetching: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=129.0.6668.89)\n",
      "Stacktrace:\n",
      "#0 0x556f9895102a <unknown>\n",
      "#1 0x556f986375e0 <unknown>\n",
      "#2 0x556f9860d1af <unknown>\n",
      "#3 0x556f986b403d <unknown>\n",
      "#4 0x556f986ca629 <unknown>\n",
      "#5 0x556f986ab8c3 <unknown>\n",
      "#6 0x556f986796b3 <unknown>\n",
      "#7 0x556f9867a68e <unknown>\n",
      "#8 0x556f9891ba2b <unknown>\n",
      "#9 0x556f9891f9b1 <unknown>\n",
      "#10 0x556f98908225 <unknown>\n",
      "#11 0x556f98920532 <unknown>\n",
      "#12 0x556f988ed38f <unknown>\n",
      "#13 0x556f9893ff28 <unknown>\n",
      "#14 0x556f989400f3 <unknown>\n",
      "#15 0x556f9894fe7c <unknown>\n",
      "#16 0x7f653e84a732 <unknown>\n",
      ". Retrying...\n",
      "Sleeping for 9.98 seconds...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 183\u001b[0m\n\u001b[1;32m    180\u001b[0m walmart_reviews \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m urls:\n\u001b[0;32m--> 183\u001b[0m     walmart_reviews\u001b[38;5;241m.\u001b[39mextend(fetch_all_reviews(url))\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# Step 7: Convert Reviews to DataFrame and Save to CSV\u001b[39;00m\n\u001b[1;32m    186\u001b[0m df_walmart \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(walmart_reviews)\n",
      "Cell \u001b[0;32mIn[1], line 155\u001b[0m, in \u001b[0;36mfetch_all_reviews\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m    152\u001b[0m page_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m?page=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# Fetch reviews for the current page\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m reviews \u001b[38;5;241m=\u001b[39m fetch_reviews_with_retry(page_url)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# If no reviews were found, stop the loop\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m reviews:\n",
      "Cell \u001b[0;32mIn[1], line 137\u001b[0m, in \u001b[0;36mfetch_reviews_with_retry\u001b[0;34m(url, max_retries)\u001b[0m\n\u001b[1;32m    135\u001b[0m     driver\u001b[38;5;241m.\u001b[39mquit()  \u001b[38;5;66;03m# Close driver before retrying\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     retries \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 137\u001b[0m     random_sleep(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m)  \u001b[38;5;66;03m# Random sleep between retries to avoid detection\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to extract reviews after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m attempts.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m []\n",
      "Cell \u001b[0;32mIn[1], line 57\u001b[0m, in \u001b[0;36mrandom_sleep\u001b[0;34m(min_delay, max_delay)\u001b[0m\n\u001b[1;32m     55\u001b[0m delay \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39muniform(min_delay, max_delay)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSleeping for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdelay\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 57\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(delay)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import undetected_chromedriver as uc\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# Step 1: Set up undetected ChromeDriver with stealth techniques\n",
    "def setup_selenium():\n",
    "    \"\"\"Set up undetected Chrome WebDriver with stealth techniques.\"\"\"\n",
    "    options = uc.ChromeOptions()\n",
    "\n",
    "    # Set a specific user agent to mimic Firefox on Linux\n",
    "    user_agent = \"Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0\"\n",
    "    options.add_argument(f\"user-agent={user_agent}\")\n",
    "\n",
    "    # Specify the path to the Chrome binary\n",
    "    \n",
    "\n",
    "    # Disable browser detection flags\n",
    "    # options.add_argument(\"--headless\")  # Use newer headless mode\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--disable-software-rasterizer\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"window-size=1920,1080\")\n",
    "    options.add_argument(\"--remote-debugging-port=9222\")\n",
    "\n",
    "\n",
    "    print(\"ChromeDriver options configured successfully.\")\n",
    "\n",
    "    # Start the Chrome WebDriver using undetected-chromedriver\n",
    "    try:\n",
    "        driver = uc.Chrome(options=options)\n",
    "        time.sleep(10) \n",
    "        print(\"ChromeDriver initialized successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing ChromeDriver: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Additional stealth techniques\n",
    "    try:\n",
    "        driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "        print(\"Stealth techniques applied successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error applying stealth techniques: {e}\")\n",
    "        return None\n",
    "\n",
    "    return driver\n",
    "\n",
    "\n",
    "# Random sleep time for human-like behavior\n",
    "def random_sleep(min_delay=2, max_delay=5):\n",
    "    \"\"\"Introduce random sleep times to simulate human behavior.\"\"\"\n",
    "    delay = random.uniform(min_delay, max_delay)\n",
    "    print(f\"Sleeping for {delay:.2f} seconds...\")\n",
    "    time.sleep(delay)\n",
    "\n",
    "# Step 2: Extract Reviews from Page using Selenium and BeautifulSoup\n",
    "def extract_reviews(page_html, url):\n",
    "    \"\"\"Extract reviews from a Walmart page using BeautifulSoup.\"\"\"\n",
    "    extracted_reviews = []\n",
    "    soup = BeautifulSoup(page_html, 'html.parser')\n",
    "    \n",
    "    # Finding all review blocks (adjust class based on actual Walmart page structure)\n",
    "    review_elements = soup.find_all('div', class_=re.compile(r'overflow-visible b--none mt\\d-l ma0 dark-gray'))\n",
    "\n",
    "    if not review_elements:\n",
    "        return None  # No reviews found, return None to trigger retry\n",
    "\n",
    "    for review in review_elements:\n",
    "        product = {}\n",
    "\n",
    "        # Extract review details\n",
    "        review_rating_element = review.select_one('.w_iUH7')\n",
    "        product['Review rating'] = review_rating_element.text if review_rating_element else None\n",
    "\n",
    "        verified_purchase_element = review.select_one('.pl2.green.b.f7.self-center')\n",
    "        product['Verified Purchase or not'] = verified_purchase_element.text if verified_purchase_element else None\n",
    "\n",
    "        review_date_element = review.select_one('.f7.gray')\n",
    "        product['Review date'] = review_date_element.text if review_date_element else None\n",
    "\n",
    "        review_title_element = review.select_one('.w_kV33.w_Sl3f.w_mvVb.f5.b')\n",
    "        product['Review title'] = review_title_element.text if review_title_element else None\n",
    "\n",
    "        review_content_element = review.select_one('span.tl-m.db-m')\n",
    "        product['Review Content'] = review_content_element.text.strip() if review_content_element else None\n",
    "\n",
    "        review_name_element = review.select_one('.f7.b.mv0')\n",
    "        product['Review name'] = review_name_element.text if review_name_element else None\n",
    "\n",
    "        # Adding the URL of the review\n",
    "        product['URL'] = url\n",
    "\n",
    "        # Append the extracted product information to the list of reviews\n",
    "        extracted_reviews.append(product)\n",
    "\n",
    "    return extracted_reviews\n",
    "\n",
    "# Step 3: Fetch Reviews with Selenium, retry if necessary\n",
    "def fetch_reviews_with_retry(url, max_retries=50):\n",
    "    \"\"\"Fetch reviews with Selenium, relaunching ChromeDriver if necessary.\"\"\"\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        print(f\"Attempt {retries + 1} of {max_retries}...\")\n",
    "\n",
    "        driver = setup_selenium()  # Re-launch ChromeDriver\n",
    "        if driver is None:\n",
    "            print(\"Failed to initialize ChromeDriver. Retrying...\")\n",
    "            retries += 1\n",
    "            random_sleep(5, 10)  # Longer delay before retry\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            random_sleep()  # Random delay to wait for the page to load\n",
    "\n",
    "            # Get the page source after it has fully loaded\n",
    "            page_html = driver.page_source\n",
    "\n",
    "            # Extract reviews using BeautifulSoup\n",
    "            reviews = extract_reviews(page_html, url)\n",
    "\n",
    "            if reviews:\n",
    "                print(f\"Successfully extracted {len(reviews)} reviews.\")\n",
    "                driver.quit()  # Close the driver after success\n",
    "                return reviews  # Return the extracted reviews\n",
    "            else:\n",
    "                print(f\"No reviews found on attempt {retries + 1}. Retrying...\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during review fetching: {e}. Retrying...\")\n",
    "\n",
    "        driver.quit()  # Close driver before retrying\n",
    "        retries += 1\n",
    "        random_sleep(5, 10)  # Random sleep between retries to avoid detection\n",
    "\n",
    "    print(f\"Failed to extract reviews after {max_retries} attempts.\")\n",
    "    return []\n",
    "\n",
    "# Step 4: Fetch All Reviews (with pagination handling if necessary)\n",
    "def fetch_all_reviews(url):\n",
    "    \"\"\"Main function to scrape reviews from all pages.\"\"\"\n",
    "    page = 1\n",
    "    all_reviews = []\n",
    "\n",
    "    while True:\n",
    "        print(f\"Fetching page {page}...\")\n",
    "\n",
    "        # Construct the URL for the current page\n",
    "        page_url = f\"{url}?page={page}\"\n",
    "\n",
    "        # Fetch reviews for the current page\n",
    "        reviews = fetch_reviews_with_retry(page_url)\n",
    "\n",
    "        # If no reviews were found, stop the loop\n",
    "        if not reviews:\n",
    "            print(f\"Stopping at page {page}. No more reviews.\")\n",
    "            break\n",
    "\n",
    "        # Add reviews to the total list\n",
    "        all_reviews.extend(reviews)\n",
    "        print(f\"Reviews extracted from page {page}: {len(reviews)}\")\n",
    "\n",
    "        # Increment the page counter\n",
    "        page += 1\n",
    "\n",
    "        # Random sleep to avoid detection\n",
    "        random_sleep()\n",
    "\n",
    "    return all_reviews\n",
    "\n",
    "# Step 5: Define Walmart URLs\n",
    "urls = [\n",
    "    'https://www.walmart.com/reviews/product/5129928603'\n",
    "]\n",
    "\n",
    "# Step 6: Scrape Reviews from All URLs\n",
    "walmart_reviews = []\n",
    "\n",
    "for url in urls:\n",
    "    walmart_reviews.extend(fetch_all_reviews(url))\n",
    "\n",
    "# Step 7: Convert Reviews to DataFrame and Save to CSV\n",
    "df_walmart = pd.DataFrame(walmart_reviews)\n",
    "\n",
    "# Post-processing and cleaning the DataFrame\n",
    "df_walmart['Retailer'] = \"Walmart\"\n",
    "df_walmart['scraping_date'] = pd.to_datetime('today').date()\n",
    "df_walmart['Review date'] = pd.to_datetime(df_walmart['Review date']).dt.date\n",
    "df_walmart['Review rating'] = df_walmart['Review rating'].str.replace(' out of 5 stars review', '').astype(float)\n",
    "df_walmart.drop_duplicates(inplace=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_walmart.to_csv('walmart_reviews.csv', index=False)\n",
    "\n",
    "print(\"Reviews scraped and saved to 'walmart_reviews.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ba7ef69-025b-4944-aab4-d9153df82b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromeDriver options configured successfully.\n",
      "ChromeDriver initialized successfully.\n",
      "Stealth techniques applied successfully.\n",
      "Fetching page 1...\n",
      "Sleeping for 2.89 seconds...\n",
      "No reviews found.\n",
      "No reviews on page 1. Restarting ChromeDriver and retrying...\n",
      "ChromeDriver options configured successfully.\n",
      "ChromeDriver initialized successfully.\n",
      "Stealth techniques applied successfully.\n",
      "Sleeping for 2.58 seconds...\n",
      "No reviews found.\n",
      "Stopping at page 1. No more reviews found.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Review date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Review date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 180\u001b[0m\n\u001b[1;32m    178\u001b[0m df_walmart[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRetailer\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWalmart\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    179\u001b[0m df_walmart[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscraping_date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoday\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdate()\n\u001b[0;32m--> 180\u001b[0m df_walmart[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReview date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df_walmart[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReview date\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdate\n\u001b[1;32m    181\u001b[0m df_walmart[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReview rating\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_walmart[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReview rating\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m out of 5 stars review\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m    182\u001b[0m df_walmart\u001b[38;5;241m.\u001b[39mdrop_duplicates(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Review date'"
     ]
    }
   ],
   "source": [
    "import undetected_chromedriver as uc\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# Step 1: Set up undetected ChromeDriver with stealth techniques\n",
    "def setup_selenium():\n",
    "    \"\"\"Set up undetected Chrome WebDriver with stealth techniques.\"\"\"\n",
    "    options = uc.ChromeOptions()\n",
    "\n",
    "    # Set a specific user agent to mimic Firefox on Linux\n",
    "    user_agent = \"Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0\"\n",
    "    options.add_argument(f\"user-agent={user_agent}\")\n",
    "\n",
    "    # Disable browser detection flags\n",
    "    # options.add_argument(\"--headless\")  # Use newer headless mode\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--disable-software-rasterizer\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"window-size=1920,1080\")\n",
    "    options.add_argument(\"--remote-debugging-port=9222\")\n",
    "\n",
    "    print(\"ChromeDriver options configured successfully.\")\n",
    "\n",
    "    # Start the Chrome WebDriver using undetected-chromedriver\n",
    "    try:\n",
    "        driver = uc.Chrome(options=options)\n",
    "        # time.sleep(10)  # Wait for ChromeDriver to initialize\n",
    "        print(\"ChromeDriver initialized successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing ChromeDriver: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Additional stealth techniques\n",
    "    try:\n",
    "        driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "        print(\"Stealth techniques applied successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error applying stealth techniques: {e}\")\n",
    "        return None\n",
    "\n",
    "    return driver\n",
    "\n",
    "# Random sleep time for human-like behavior\n",
    "def random_sleep(min_delay=2, max_delay=5):\n",
    "    \"\"\"Introduce random sleep times to simulate human behavior.\"\"\"\n",
    "    delay = random.uniform(min_delay, max_delay)\n",
    "    print(f\"Sleeping for {delay:.2f} seconds...\")\n",
    "    time.sleep(delay)\n",
    "\n",
    "# Step 2: Extract Reviews from Page using Selenium and BeautifulSoup\n",
    "def extract_reviews(page_html, url):\n",
    "    \"\"\"Extract reviews from a Walmart page using BeautifulSoup.\"\"\"\n",
    "    extracted_reviews = []\n",
    "    soup = BeautifulSoup(page_html, 'html.parser')\n",
    "\n",
    "    # Finding all review blocks (adjust class based on actual Walmart page structure)\n",
    "    review_elements = soup.find_all('div', class_=re.compile(r'overflow-visible b--none mt\\d-l ma0 dark-gray'))\n",
    "\n",
    "    if not review_elements:\n",
    "        return None  # No reviews found, return None to trigger retry\n",
    "\n",
    "    for review in review_elements:\n",
    "        product = {}\n",
    "\n",
    "        # Extract review details\n",
    "        review_rating_element = review.select_one('.w_iUH7')\n",
    "        product['Review rating'] = review_rating_element.text if review_rating_element else None\n",
    "\n",
    "        verified_purchase_element = review.select_one('.pl2.green.b.f7.self-center')\n",
    "        product['Verified Purchase or not'] = verified_purchase_element.text if verified_purchase_element else None\n",
    "\n",
    "        review_date_element = review.select_one('.f7.gray')\n",
    "        product['Review date'] = review_date_element.text if review_date_element else None\n",
    "\n",
    "        review_title_element = review.select_one('.w_kV33.w_Sl3f.w_mvVb.f5.b')\n",
    "        product['Review title'] = review_title_element.text if review_title_element else None\n",
    "\n",
    "        review_content_element = review.select_one('span.tl-m.db-m')\n",
    "        product['Review Content'] = review_content_element.text.strip() if review_content_element else None\n",
    "\n",
    "        review_name_element = review.select_one('.f7.b.mv0')\n",
    "        product['Review name'] = review_name_element.text if review_name_element else None\n",
    "\n",
    "        # Adding the URL of the review\n",
    "        product['URL'] = url\n",
    "\n",
    "        # Append the extracted product information to the list of reviews\n",
    "        extracted_reviews.append(product)\n",
    "\n",
    "    return extracted_reviews\n",
    "\n",
    "# Step 3: Fetch Reviews with Selenium, only restart driver if necessary\n",
    "def fetch_reviews(driver, url):\n",
    "    \"\"\"Fetch reviews with Selenium and restart ChromeDriver only if no reviews are found.\"\"\"\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        random_sleep()  # Random delay to wait for the page to load\n",
    "\n",
    "        # Get the page source after it has fully loaded\n",
    "        page_html = driver.page_source\n",
    "\n",
    "        # Extract reviews using BeautifulSoup\n",
    "        reviews = extract_reviews(page_html, url)\n",
    "\n",
    "        if reviews:\n",
    "            print(f\"Successfully extracted {len(reviews)} reviews.\")\n",
    "            return reviews  # Return the extracted reviews\n",
    "        else:\n",
    "            print(\"No reviews found.\")\n",
    "            return None  # Return None if no reviews are found\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during review fetching: {e}\")\n",
    "        return None\n",
    "\n",
    "# Step 4: Fetch All Reviews (with pagination handling if necessary)\n",
    "def fetch_all_reviews(url):\n",
    "    \"\"\"Main function to scrape reviews from all pages.\"\"\"\n",
    "    page = 1\n",
    "    all_reviews = []\n",
    "\n",
    "    driver = setup_selenium()  # Set up ChromeDriver initially\n",
    "\n",
    "    while True:\n",
    "        print(f\"Fetching page {page}...\")\n",
    "\n",
    "        # Construct the URL for the current page\n",
    "        page_url = f\"{url}?page={page}\"\n",
    "\n",
    "        # Fetch reviews for the current page\n",
    "        reviews = fetch_reviews(driver, page_url)\n",
    "\n",
    "        # If no reviews were found, restart the driver and retry the current page\n",
    "        if not reviews:\n",
    "            print(f\"No reviews on page {page}. Restarting ChromeDriver and retrying...\")\n",
    "            driver.quit()  # Quit the driver\n",
    "            driver = setup_selenium()  # Restart ChromeDriver\n",
    "            if driver is None:\n",
    "                print(\"Failed to restart ChromeDriver.\")\n",
    "                break  # If driver fails to restart, stop the loop\n",
    "            reviews = fetch_reviews(driver, page_url)  # Retry fetching reviews\n",
    "            if not reviews:\n",
    "                print(f\"Stopping at page {page}. No more reviews found.\")\n",
    "                break\n",
    "\n",
    "        # Add reviews to the total list\n",
    "        all_reviews.extend(reviews)\n",
    "        print(f\"Reviews extracted from page {page}: {len(reviews)}\")\n",
    "\n",
    "        # Increment the page counter\n",
    "        page += 1\n",
    "\n",
    "        # Random sleep to avoid detection\n",
    "        random_sleep()\n",
    "\n",
    "    driver.quit()  # Close the driver after all reviews are fetched\n",
    "    return all_reviews\n",
    "\n",
    "# Step 5: Define Walmart URLs\n",
    "urls = [\n",
    "    'https://www.walmart.com/reviews/product/5129928603'\n",
    "]\n",
    "\n",
    "# Step 6: Scrape Reviews from All URLs\n",
    "walmart_reviews = []\n",
    "\n",
    "for url in urls:\n",
    "    walmart_reviews.extend(fetch_all_reviews(url))\n",
    "\n",
    "# Step 7: Convert Reviews to DataFrame and Save to CSV\n",
    "df_walmart = pd.DataFrame(walmart_reviews)\n",
    "\n",
    "# Post-processing and cleaning the DataFrame\n",
    "df_walmart['Retailer'] = \"Walmart\"\n",
    "df_walmart['scraping_date'] = pd.to_datetime('today').date()\n",
    "df_walmart['Review date'] = pd.to_datetime(df_walmart['Review date']).dt.date\n",
    "df_walmart['Review rating'] = df_walmart['Review rating'].str.replace(' out of 5 stars review', '').astype(float)\n",
    "df_walmart.drop_duplicates(inplace=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_walmart.to_csv('walmart_reviews.csv', index=False)\n",
    "\n",
    "print(\"Reviews scraped and saved to 'walmart_reviews.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0be71f0-b478-4bfb-828a-9e39344c2902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching page 1...\n",
      "Attempt 1 of 50...\n",
      "ChromeDriver options configured successfully.\n",
      "ChromeDriver initialized successfully.\n"
     ]
    },
    {
     "ename": "InvalidCookieDomainException",
     "evalue": "Message: invalid cookie domain: Cookie 'domain' mismatch\n  (Session info: chrome=129.0.6668.89)\nStacktrace:\n#0 0x555ec0de402a <unknown>\n#1 0x555ec0aca5e0 <unknown>\n#2 0x555ec0b6f9d9 <unknown>\n#3 0x555ec0b3eb22 <unknown>\n#4 0x555ec0b5dd7d <unknown>\n#5 0x555ec0b3e8c3 <unknown>\n#6 0x555ec0b0c6b3 <unknown>\n#7 0x555ec0b0d68e <unknown>\n#8 0x555ec0daea2b <unknown>\n#9 0x555ec0db29b1 <unknown>\n#10 0x555ec0d9b225 <unknown>\n#11 0x555ec0db3532 <unknown>\n#12 0x555ec0d8038f <unknown>\n#13 0x555ec0dd2f28 <unknown>\n#14 0x555ec0dd30f3 <unknown>\n#15 0x555ec0de2e7c <unknown>\n#16 0x7fa97c786732 <unknown>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidCookieDomainException\u001b[0m              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 471\u001b[0m\n\u001b[1;32m    468\u001b[0m walmart_reviews \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m urls:\n\u001b[0;32m--> 471\u001b[0m     walmart_reviews\u001b[38;5;241m.\u001b[39mextend(fetch_all_reviews(url, cookies))\n\u001b[1;32m    473\u001b[0m \u001b[38;5;66;03m# Step 8: Convert Reviews to DataFrame and Save to CSV\u001b[39;00m\n\u001b[1;32m    474\u001b[0m df_walmart \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(walmart_reviews)\n",
      "Cell \u001b[0;32mIn[5], line 158\u001b[0m, in \u001b[0;36mfetch_all_reviews\u001b[0;34m(url, cookies)\u001b[0m\n\u001b[1;32m    155\u001b[0m page_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m?page=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# Fetch reviews for the current page\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m reviews \u001b[38;5;241m=\u001b[39m fetch_reviews_with_retry(page_url, cookies)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# If no reviews were found, stop the loop\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m reviews:\n",
      "Cell \u001b[0;32mIn[5], line 111\u001b[0m, in \u001b[0;36mfetch_reviews_with_retry\u001b[0;34m(url, cookies, max_retries)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m retries \u001b[38;5;241m<\u001b[39m max_retries:\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mretries\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 111\u001b[0m     driver \u001b[38;5;241m=\u001b[39m setup_selenium(cookies)  \u001b[38;5;66;03m# Re-launch ChromeDriver with cookies\u001b[39;00m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m driver \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to initialize ChromeDriver. Retrying...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 41\u001b[0m, in \u001b[0;36msetup_selenium\u001b[0;34m(cookies)\u001b[0m\n\u001b[1;32m     38\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)  \u001b[38;5;66;03m# Wait for the page to load before injecting cookies\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cookie \u001b[38;5;129;01min\u001b[39;00m cookies:\n\u001b[0;32m---> 41\u001b[0m     driver\u001b[38;5;241m.\u001b[39madd_cookie(cookie)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCookies injected successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Additional stealth techniques\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py:643\u001b[0m, in \u001b[0;36mWebDriver.add_cookie\u001b[0;34m(self, cookie_dict)\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mADD_COOKIE, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcookie\u001b[39m\u001b[38;5;124m\"\u001b[39m: cookie_dict})\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mADD_COOKIE, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcookie\u001b[39m\u001b[38;5;124m\"\u001b[39m: cookie_dict})\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py:354\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m--> 354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[1;32m    355\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/selenium/webdriver/remote/errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mInvalidCookieDomainException\u001b[0m: Message: invalid cookie domain: Cookie 'domain' mismatch\n  (Session info: chrome=129.0.6668.89)\nStacktrace:\n#0 0x555ec0de402a <unknown>\n#1 0x555ec0aca5e0 <unknown>\n#2 0x555ec0b6f9d9 <unknown>\n#3 0x555ec0b3eb22 <unknown>\n#4 0x555ec0b5dd7d <unknown>\n#5 0x555ec0b3e8c3 <unknown>\n#6 0x555ec0b0c6b3 <unknown>\n#7 0x555ec0b0d68e <unknown>\n#8 0x555ec0daea2b <unknown>\n#9 0x555ec0db29b1 <unknown>\n#10 0x555ec0d9b225 <unknown>\n#11 0x555ec0db3532 <unknown>\n#12 0x555ec0d8038f <unknown>\n#13 0x555ec0dd2f28 <unknown>\n#14 0x555ec0dd30f3 <unknown>\n#15 0x555ec0de2e7c <unknown>\n#16 0x7fa97c786732 <unknown>\n"
     ]
    }
   ],
   "source": [
    "import undetected_chromedriver as uc\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# Step 1: Set up undetected ChromeDriver with stealth techniques\n",
    "def setup_selenium(cookies):\n",
    "    \"\"\"Set up undetected Chrome WebDriver with stealth techniques and inject cookies.\"\"\"\n",
    "    options = uc.ChromeOptions()\n",
    "\n",
    "    # Set a specific user agent to mimic Firefox on Linux\n",
    "    user_agent = \"Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0\"\n",
    "    options.add_argument(f\"user-agent={user_agent}\")\n",
    "\n",
    "    # Disable browser detection flags\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--disable-software-rasterizer\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"window-size=1920,1080\")\n",
    "    options.add_argument(\"--remote-debugging-port=9222\")\n",
    "\n",
    "    print(\"ChromeDriver options configured successfully.\")\n",
    "\n",
    "    # Start the Chrome WebDriver using undetected-chromedriver\n",
    "    try:\n",
    "        driver = uc.Chrome(options=options)\n",
    "        time.sleep(5)  # Wait for ChromeDriver to initialize\n",
    "        print(\"ChromeDriver initialized successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing ChromeDriver: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Inject cookies into the session\n",
    "    driver.get(\"https://www.walmart.com\")  # Open Walmart homepage to set cookies for the correct domain\n",
    "    time.sleep(5)  # Wait for the page to load before injecting cookies\n",
    "\n",
    "    for cookie in cookies:\n",
    "        driver.add_cookie(cookie)\n",
    "\n",
    "    print(\"Cookies injected successfully.\")\n",
    "\n",
    "    # Additional stealth techniques\n",
    "    try:\n",
    "        driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "        print(\"Stealth techniques applied successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error applying stealth techniques: {e}\")\n",
    "        return None\n",
    "\n",
    "    return driver\n",
    "\n",
    "# Random sleep time for human-like behavior\n",
    "def random_sleep(min_delay=2, max_delay=5):\n",
    "    \"\"\"Introduce random sleep times to simulate human behavior.\"\"\"\n",
    "    delay = random.uniform(min_delay, max_delay)\n",
    "    print(f\"Sleeping for {delay:.2f} seconds...\")\n",
    "    time.sleep(delay)\n",
    "\n",
    "# Step 2: Extract Reviews from Page using Selenium and BeautifulSoup\n",
    "def extract_reviews(page_html, url):\n",
    "    \"\"\"Extract reviews from a Walmart page using BeautifulSoup.\"\"\"\n",
    "    extracted_reviews = []\n",
    "    soup = BeautifulSoup(page_html, 'html.parser')\n",
    "\n",
    "    # Finding all review blocks (adjust class based on actual Walmart page structure)\n",
    "    review_elements = soup.find_all('div', class_=re.compile(r'overflow-visible b--none mt\\d-l ma0 dark-gray'))\n",
    "\n",
    "    if not review_elements:\n",
    "        return None  # No reviews found, return None to trigger retry\n",
    "\n",
    "    for review in review_elements:\n",
    "        product = {}\n",
    "\n",
    "        # Extract review details\n",
    "        review_rating_element = review.select_one('.w_iUH7')\n",
    "        product['Review rating'] = review_rating_element.text if review_rating_element else None\n",
    "\n",
    "        verified_purchase_element = review.select_one('.pl2.green.b.f7.self-center')\n",
    "        product['Verified Purchase or not'] = verified_purchase_element.text if verified_purchase_element else None\n",
    "\n",
    "        review_date_element = review.select_one('.f7.gray')\n",
    "        product['Review date'] = review_date_element.text if review_date_element else None\n",
    "\n",
    "        review_title_element = review.select_one('.w_kV33.w_Sl3f.w_mvVb.f5.b')\n",
    "        product['Review title'] = review_title_element.text if review_title_element else None\n",
    "\n",
    "        review_content_element = review.select_one('span.tl-m.db-m')\n",
    "        product['Review Content'] = review_content_element.text.strip() if review_content_element else None\n",
    "\n",
    "        review_name_element = review.select_one('.f7.b.mv0')\n",
    "        product['Review name'] = review_name_element.text if review_name_element else None\n",
    "\n",
    "        # Adding the URL of the review\n",
    "        product['URL'] = url\n",
    "\n",
    "        # Append the extracted product information to the list of reviews\n",
    "        extracted_reviews.append(product)\n",
    "\n",
    "    return extracted_reviews\n",
    "\n",
    "# Step 3: Fetch Reviews with Selenium, retry if necessary\n",
    "def fetch_reviews_with_retry(url, cookies, max_retries=50):\n",
    "    \"\"\"Fetch reviews with Selenium, relaunching ChromeDriver if necessary.\"\"\"\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        print(f\"Attempt {retries + 1} of {max_retries}...\")\n",
    "\n",
    "        driver = setup_selenium(cookies)  # Re-launch ChromeDriver with cookies\n",
    "        if driver is None:\n",
    "            print(\"Failed to initialize ChromeDriver. Retrying...\")\n",
    "            retries += 1\n",
    "            random_sleep(5, 10)  # Longer delay before retry\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            random_sleep()  # Random delay to wait for the page to load\n",
    "\n",
    "            # Get the page source after it has fully loaded\n",
    "            page_html = driver.page_source\n",
    "\n",
    "            # Extract reviews using BeautifulSoup\n",
    "            reviews = extract_reviews(page_html, url)\n",
    "\n",
    "            if reviews:\n",
    "                print(f\"Successfully extracted {len(reviews)} reviews.\")\n",
    "                driver.quit()  # Close the driver after success\n",
    "                return reviews  # Return the extracted reviews\n",
    "            else:\n",
    "                print(f\"No reviews found on attempt {retries + 1}. Retrying...\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during review fetching: {e}. Retrying...\")\n",
    "\n",
    "        driver.quit()  # Close driver before retrying\n",
    "        retries += 1\n",
    "        random_sleep(5, 10)  # Random sleep between retries to avoid detection\n",
    "\n",
    "    print(f\"Failed to extract reviews after {max_retries} attempts.\")\n",
    "    return []\n",
    "\n",
    "# Step 4: Fetch All Reviews (with pagination handling if necessary)\n",
    "def fetch_all_reviews(url, cookies):\n",
    "    \"\"\"Main function to scrape reviews from all pages.\"\"\"\n",
    "    page = 1\n",
    "    all_reviews = []\n",
    "\n",
    "    while True:\n",
    "        print(f\"Fetching page {page}...\")\n",
    "\n",
    "        # Construct the URL for the current page\n",
    "        page_url = f\"{url}?page={page}\"\n",
    "\n",
    "        # Fetch reviews for the current page\n",
    "        reviews = fetch_reviews_with_retry(page_url, cookies)\n",
    "\n",
    "        # If no reviews were found, stop the loop\n",
    "        if not reviews:\n",
    "            print(f\"Stopping at page {page}. No more reviews.\")\n",
    "            break\n",
    "\n",
    "        # Add reviews to the total list\n",
    "        all_reviews.extend(reviews)\n",
    "        print(f\"Reviews extracted from page {page}: {len(reviews)}\")\n",
    "\n",
    "        # Increment the page counter\n",
    "        page += 1\n",
    "\n",
    "        # Random sleep to avoid detection\n",
    "        random_sleep()\n",
    "\n",
    "    return all_reviews\n",
    "\n",
    "# Step 5: Convert cookie data to ChromeDriver's cookie format\n",
    "def format_cookies(raw_cookies):\n",
    "    \"\"\"Convert raw cookie data to the format required by ChromeDriver.\"\"\"\n",
    "    formatted_cookies = []\n",
    "    for raw_cookie in raw_cookies:\n",
    "        cookie = {\n",
    "            'name': raw_cookie.get('Name raw'),\n",
    "            'value': raw_cookie.get('Content raw'),\n",
    "            'domain': raw_cookie.get('Host raw').replace(\"http://\", \"\").replace(\"https://\", \"\").replace(\"www.\", \"\"),\n",
    "            'path': raw_cookie.get('Path raw'),\n",
    "            'expiry': int(raw_cookie.get('Expires raw')) if raw_cookie.get('Expires raw') != '0' else None,\n",
    "            'secure': raw_cookie.get('Send for raw') == 'true',\n",
    "            'httpOnly': raw_cookie.get('HTTP only raw') == 'true'\n",
    "        }\n",
    "        formatted_cookies.append(cookie)\n",
    "    return formatted_cookies\n",
    "\n",
    "# Step 6: Define Walmart URLs and Raw Cookies\n",
    "urls = [\n",
    "    'https://www.walmart.com/reviews/product/5129928603'\n",
    "]\n",
    "\n",
    "raw_cookies = [\n",
    "    {\n",
    "        \"Host raw\": \"https://drfdisvc.walmart.com/\",\n",
    "        \"Name raw\": \"thx_guid\",\n",
    "        \"Path raw\": \"/\",\n",
    "        \"Content raw\": \"695992473ab83a5fc29f753ea1039108\",\n",
    "        \"Expires raw\": \"1879753265\",\n",
    "        \"Send for raw\": \"true\",\n",
    "        \"HTTP only raw\": \"true\"\n",
    "    },\n",
    "    {\n",
    "        \"Host raw\": \"https://identity.walmart.com/\",\n",
    "        \"Name raw\": \"locGuestData\",\n",
    "        \"Path raw\": \"/\",\n",
    "        \"Content raw\": \"eyJpbnRlbnQiOiJTSElQUElORyIsImlzRXhwbGljaXQiOmZhbHNlLCJzdG9yZUludGVudCI6IlBJQ0tVUCIsIm1lcmdlRmxhZyI6ZmFsc2UsImlzRGVmYXVsdGVkIjp0cnVlLCJwaWNrdXAiOnsibm9kZUlkIjoiMzA4MSIsInRpbWVzdGFtcCI6MTcyNjk0NDA2NDk1OSwic2VsZWN0aW9uVHlwZSI6IkRFRkFVTFRFRCJ9LCJzaGlwcGluZ0FkZHJlc3MiOnsidGltZXN0YW1wIjoxNzI2OTQ0MDY0OTU5LCJ0eXBlIjoicGFydGlhbC1sb2NhdGlvbiIsImdpZnRBZGRyZXNzIjpmYWxzZSwicG9zdGFsQ29kZSI6Ijk1ODI5IiwiZGVsaXZlcnlTdG9yZUxpc3QiOlt7Im5vZGVJZCI6IjMwODEiLCJ0eXBlIjoiREVMSVZFUlkiLCJ0aW1lc3RhbXAiOjE3MjY5NDQwNjQ5NDUsImRlbGl2ZXJ5VGllciI6bnVsbCwic2VsZWN0aW9uVHlwZSI6IkRFRkFVTFRFRCIsInNlbGVjdGlvblNvdXJjZSI6bnVsbH1dLCJjaXR5IjoiU2FjcmFtZW50byIsInN0YXRlIjoiQ0EifSwicG9zdGFsQ29kZSI6eyJ0aW1lc3RhbXAiOjE3MjY5NDQwNjQ5NTksImJhc2UiOiI5NTgyOSJ9LCJtcCI6W10sIm1zcCI6eyJub2RlSWRzIjpbXSwidGltZXN0YW1wIjpudWxsfSwidmFsaWRhdGVLZXkiOiJwcm9kOnYyOjIwZGE1MWIwLWNmYzItNDZiNC05ZWNhLTZlNjAyNWZkNTBhMSJ9\",\n",
    "        \"Expires raw\": \"1758480065\",\n",
    "        \"Send for raw\": \"true\",\n",
    "        \"HTTP only raw\": \"true\"\n",
    "    },\n",
    "    {\n",
    "        \"Host raw\": \"https://identity.walmart.com/\",\n",
    "        \"Name raw\": \"userAppVersion\",\n",
    "        \"Path raw\": \"/\",\n",
    "        \"Content raw\": \"us-web-1.160.0-e7b8d8136f0ca2c796140aa8f52c5f4d1b49c7b0-091816\",\n",
    "        \"Expires raw\": \"1758480065\",\n",
    "        \"Send for raw\": \"true\",\n",
    "        \"HTTP only raw\": \"false\"\n",
    "    },\n",
    "    {\n",
    "        \"Host raw\": \"http://identity.walmart.com/\",\n",
    "        \"Name raw\": \"_pxhd\",\n",
    "        \"Path raw\": \"/\",\n",
    "        \"Content raw\": \"ceabe07eaa553b4280b1b7d71fd5e683fb59d85a80f7cfcd82bcda47d40e63b9:7ac1ccf5-5fa1-11ef-864e-d0cd5ff06627\",\n",
    "        \"Expires raw\": \"1758480089\",\n",
    "        \"Send for raw\": \"false\",\n",
    "        \"HTTP only raw\": \"false\"\n",
    "    },\n",
    "    {\n",
    "        \"Host raw\": \"http://tap.walmart.com/\",\n",
    "        \"Name raw\": \"TS2a5e0c5c027\",\n",
    "        \"Path raw\": \"/\",\n",
    "        \"Content raw\": \"08b0b9c65dab20004b5d11191b366f74081ee7f3afb22ad16748024b018281741a0493d6db4b315b086396a6841130004e164d4767ef664a647e2e23e2500b46243e58ed41956075a25fea2da78841cbc46a50b226d94e84fdbe19fb96363e30\",\n",
    "        \"Expires raw\": \"0\",\n",
    "        \"Send for raw\": \"false\",\n",
    "        \"HTTP only raw\": \"false\"\n",
    "    },\n",
    "    {\n",
    "        \"Host raw\": \"http://identity.walmart.com/\",\n",
    "        \"Name raw\": \"TS013f65e0\",\n",
    "        \"Path raw\": \"/\",\n",
    "        \"Content raw\": \"01816dd022dff3e210457ca19a7e5e3ddc4dc273392bb7eadc6db2916ac13642a7ae25a5f16992fcb431c6403e1cac6b4dc59172ea\",\n",
    "        \"Expires raw\": \"0\",\n",
    "        \"Send for raw\": \"false\",\n",
    "        \"HTTP only raw\": \"false\"\n",
    "    },\n",
    "    {\n",
    "        \"Host raw\": \"http://identity.walmart.com/\",\n",
    "        \"Name raw\": \"TS2a5e0c5c027\",\n",
    "        \"Path raw\": \"/\",\n",
    "        \"Content raw\": \"08046e0832ab2000d001e8b18a638002dea1a3687a9cf89f555568439c3511f62100fab902da6ca1088d1ae757113000173177d7bdc650dfc318f021fb711441aa924d9bb7ac2cbd13c3b38e5418c457c64acd831e3d2a52b9b1d80c4c4319e3\",\n",
    "        \"Expires raw\": \"0\",\n",
    "        \"Send for raw\": \"false\",\n",
    "        \"HTTP only raw\": \"false\"\n",
    "    },\n",
    "    {\n",
    "        \"Host raw\": \"http://identity.walmart.com/\",\n",
    "        \"Name raw\": \"TS016ef4c8\",\n",
    "        \"Path raw\": \"/\",\n",
    "        \"Content raw\": \"01144c8cd2cb2d125761b09834229f7882e69c8abb911278bd94f099210056a4f43c6c5035a00af1f10f6a06c76a5117f331eb5e09\",\n",
    "        \"Expires raw\": \"0\",\n",
    "        \"Send for raw\": \"false\",\n",
    "        \"HTTP only raw\": \"false\"\n",
    "    },\n",
    "    {\n",
    "        \"Host raw\": \"http://identity.walmart.com/\",\n",
    "        \"Name raw\": \"TS8cb5a80e027\",\n",
    "        \"Path raw\": \"/\",\n",
    "        \"Content raw\": \"08faef4f78ab2000f2d968ab933894cbaafd4c637aca7a58702cba9222836e7e7263d5ec8027d5a208905f757e1130004d8cc94180ef280e204311c8d54675e2c955e1ff1b73ac150466c2416b86962e0a417ecdd37b87944c0c46187994c071\",\n",
    "        \"Expires raw\": \"0\",\n",
    "        \"Send for raw\": \"false\",\n",
    "        \"HTTP only raw\": \"false\"\n",
    "    },\n",
    "    {\n",
    "        \"Host raw\": \"http://beacon.walmart.com/\",\n",
    "        \"Name raw\": \"bsc\",\n",
    "        \"Path raw\": \"/\",\n",
    "        \"Content raw\": \"VqLPWatmibTk42IIYqRX0Q\",\n",
    "        \"Expires raw\": \"0\",\n",
    "        \"Send for raw\": \"false\",\n",
    "        \"HTTP only raw\": \"false\"\n",
    "    },\n",
    "    {\n",
    "        \"Host raw\": \"http://beacon.walmart.com/\",\n",
    "        \"Name raw\": \"_tap_path\",\n",
    "        \"Path raw\": \"/\",\n",
    "        \"Content raw\": \"/rum.gif\",\n",
    "        \"Expires raw\": \"0\",\n",
    "        \"Send for raw\": \"false\",\n",
    "        \"HTTP only raw\": \"false\"\n",
    "    },\n",
    "    {\n",
    "        \"Host raw\": \"http://beacon.walmart.com/\",\n",
    "        \"Name raw\": \"_tap-criteo\",\n",
    "        \"Path raw\": \"/\",\n",
    "        \"Content raw\": \"1728213127506:1728213129585:1\",\n",
    "        \"Expires raw\": \"1729422729\",\n",
    "        \"Send for raw\": \"false\",\n",
    "        \"HTTP only raw\": \"false\"\n",
    "    },\n",
    "    {\n",
    "        \"Host raw\": \"http://beacon.walmart.com/\",\n",
    "        \"Name raw\": \"_tap-lrB\",\n",
    "        \"Path raw\": \"/\",\n",
    "        \"Content raw\": \"1728213129584:0:1\",\n",
    "        \"Expires raw\": \"1729422729\",\n",
    "        \"Send for raw\": \"false\",\n",
    "        \"HTTP only raw\": \"false\"\n",
    "    },\n",
    "    {\n",
    "        \"Host raw\": \"http://beacon.walmart.com/\",\n",
    "        \"Name raw\": \"_tap-lrV\",\n",
    "        \"Path raw\": \"/\",\n",
    "        \"Content raw\": \"1728213134484:0:1\",\n",
    "        \"Expires raw\": \"1729422734\",\n",
    "        \"Send for raw\": \"false\",\n",
    "        \"HTTP only raw\": \"false\"\n",
    "    },\n",
    "    {\n",
    "        \"Host raw\": \"http://beacon.walmart.com/\",\n",
    "        \"Name raw\": \"_tap-wmt-dw\",\n",
    "        \"Path raw\": \"/\",\n",
    "        \"Content raw\": \"1728213167814:1728213169142:1\",\n",
    "        \"Expires raw\": \"1729422769\",\n",
    "        \"Send for raw\": \"false\",\n",
    "        \"HTTP only raw\": \"false\"\n",
    "    },\n",
    "    {\n",
    "        \"Host raw\": \"http://beacon.walmart.com/\",\n",
    "        \"Name raw\": \"_tap-googdsp\",\n",
    "        \"Path raw\": \"/\",\n",
    "        \"Content raw\": \"1728213169141:0:1\",\n",
    "        \"Expires raw\": \"1728213769\",\n",
    "        \"Send for raw\": \"false\",\n",
    "        \"HTTP only raw\": \"false\"\n",
    "    },\n",
    "    {\n",
    "        \"Host raw\": \"http://beacon.walmart.com/\",\n",
    "        \"Name raw\": \"_tap-appnexus\",\n",
    "        \"Path raw\": \"/\",\n",
    "        \"Content raw\": \"1728213138897:0:2\",\n",
    "        \"Expires raw\": \"1729422795\",\n",
    "        \"Send for raw\": \"false\",\n",
    "        \"HTTP only raw\": \"false\"\n",
    "    },\n",
    "    {\n",
    "        \"Host raw\": \"http://beacon.walmart.com/\",\n",
    "        \"Name raw\": \"btc\",\n",
    "        \"Path raw\": \"/\",\n",
    "        \"Content raw\": \"Zdk8B67IkX6yJUy6I9lBhY\",\n",
    "        \"Expires raw\": \"2043789216\",\n",
    "        \"Send for raw\": \"false\",\n",
    "        \"HTTP only raw\": \"false\"\n",
    "    },\n",
    "    {\n",
    "        \"Host raw\": \"http://beacon.walmart.com/\",\n",
    "        \"Name raw\": \"b30msc\",\n",
    "        \"Path raw\": \"/\",\n",
    "        \"Content raw\": \"TPd2HjHFGe8sc-1wf3j8ME\",\n",
    "        \"Expires raw\": \"1728215016\",\n",
    "        \"Send for raw\": \"false\",\n",
    "        \"HTTP only raw\": \"false\"\n",
    "    },\n",
    "    {\n",
    "        \"Host raw\": \"http://b.www.walmart.com/\",\n",
    "        \"Name raw\": \"bsc\",\n",
    "        \"Path raw\": \"/\",\n",
    "        \"Content raw\": \"dtf2pVFcLW2woLI2E9bsUI\",\n",
    "        \"Expires raw\": \"0\",\n",
    "        \"Send for raw\": \"false\",\n",
    "        \"HTTP only raw\": \"false\"\n",
    "    },\n",
    "    {\n",
    "        \"Host raw\": \"http://b.www.walmart.com/\",\n",
    "        \"Name raw\": \"_tap_path\",\n",
    "        \"Path raw\": \"/\",\n",
    "        \"Content raw\": \"/rum.gif\",\n",
    "        \"Expires raw\": \"0\",\n",
    "        \"Send for raw\": \"false\",\n",
    "        \"HTTP only raw\": \"false\"\n",
    "    },\n",
    "    {\n",
    "        \"Host raw\": \"http://b.www.walmart.com/\",\n",
    "        \"Name raw\": \"_tap-criteo\",\n",
    "        \"Path raw\": \"/\",\n",
    "        \"Content raw\": \"1728213217898:1728213218528:1\",\n",
    "        \"Expires raw\": \"1729422818\",\n",
    "        \"Send for raw\": \"false\",\n",
    "        \"HTTP only raw\": \"false\"\n",
    "    },\n",
    "    {\n",
    "        \"Host raw\": \"http://b.www.walmart.com/\",\n",
    "        \"Name raw\": \"_tap-lrB\",\n",
    "        \"Path raw\": \"/\",\n",
    "        \"Content raw\": \"1728213218527:0:1\",\n",
    "        \"Expires raw\": \"1729422818\",\n",
    "        \"Send for raw\": \"false\",\n",
    "        \"HTTP only raw\": \"false\"\n",
    "    },\n",
    "    {\n",
    "        \"Host raw\": \"http://.walmart.com/\",\n",
    "        \"Name raw\": \"AID\",\n",
    "        \"Path raw\": \"/\",\n",
    "        \"Content raw\": \"wmlspartner%3D0%3Areflectorid%3D0000000000000000000000%3Alastupd%3D1728213222366\",\n",
    "        \"Expires raw\": \"2043573222\",\n",
    "        \"Send for raw\": \"false\",\n",
    "        \"HTTP only raw\": \"true\"\n",
    "    },\n",
    "    {\n",
    "        \"Host raw\": \"http://.walmart.com/\",\n",
    "        \"Name raw\": \"com.wm.reflector\",\n",
    "        \"Path raw\": \"/\",\n",
    "        \"Content raw\": \"%22reflectorid%3A0000000000000000000000%40lastupd%3A1728213222366%40firstcreate%3A1728213222366%22\",\n",
    "        \"Expires raw\": \"2043573222\",\n",
    "        \"Send for raw\": \"false\",\n",
    "        \"HTTP only raw\": \"false\"\n",
    "    },\n",
    "    {\n",
    "        \"Host raw\": \"https://.www.walmart.com/\",\n",
    "        \"Name raw\": \"ACID\",\n",
    "        \"Path raw\": \"/\",\n",
    "        \"Content raw\": \"fff2fa77-0bb3-43a8-9a7c-4ae78cfc76b7\",\n",
    "        \"Expires raw\": \"1759749222\",\n",
    "        \"Send for raw\": \"true\",\n",
    "        \"HTTP only raw\": \"true\"\n",
    "    },\n",
    "    {\n",
    "        \"Host raw\": \"https://www.walmart.com/\",\n",
    "        \"Name raw\": \"_intlbu\",\n",
    "        \"Path raw\": \"/\",\n",
    "        \"Content raw\": \"false\",\n",
    "        \"Expires raw\": \"1728216822\",\n",
    "        \"Send for raw\": \"true\",\n",
    "        \"HTTP only raw\": \"false\"\n",
    "    },\n",
    "    {\n",
    "        \"Host raw\": \"https://www.walmart.com/\",\n",
    "        \"Name raw\": \"_shcc\",\n",
    "        \"Path raw\": \"/\",\n",
    "        \"Content raw\": \"US\",\n",
    "        \"Expires raw\": \"1728216822\",\n",
    "        \"Send for raw\": \"true\",\n",
    "        \"HTTP only raw\": \"false\"\n",
    "    },\n",
    "    {\n",
    "        \"Host raw\": \"https://www.walmart.com/\",\n",
    "        \"Name raw\": \"assortmentStoreId\",\n",
    "        \"Path raw\": \"/\",\n",
    "        \"Content raw\": \"3081\",\n",
    "        \"Expires raw\": \"1728216822\",\n",
    "        \"Send for raw\": \"true\",\n",
    "        \"HTTP only raw\": \"false\"\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "cookies = format_cookies(raw_cookies)  # Format cookies to be used with ChromeDriver\n",
    "\n",
    "# Step 7: Scrape Reviews from All URLs\n",
    "walmart_reviews = []\n",
    "\n",
    "for url in urls:\n",
    "    walmart_reviews.extend(fetch_all_reviews(url, cookies))\n",
    "\n",
    "# Step 8: Convert Reviews to DataFrame and Save to CSV\n",
    "df_walmart = pd.DataFrame(walmart_reviews)\n",
    "\n",
    "# Post-processing and cleaning the DataFrame\n",
    "df_walmart['Retailer'] = \"Walmart\"\n",
    "df_walmart['scraping_date'] = pd.to_datetime('today').date()\n",
    "df_walmart['Review date'] = pd.to_datetime(df_walmart['Review date']).dt.date\n",
    "df_walmart['Review rating'] = df_walmart['Review rating'].str.replace(' out of 5 stars review', '').astype(float)\n",
    "df_walmart.drop_duplicates(inplace=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_walmart.to_csv('walmart_reviews.csv', index=False)\n",
    "\n",
    "print(\"Reviews scraped and saved to 'walmart_reviews.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08eb22f-ea8a-4b23-a81f-8eb7ebc0936e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
